# PDF to Text Extraction Pipeline

A clean, efficient pipeline for extracting structured text and table data from Persian/Arabic PDFs (energy consumption bills).

## ğŸ“ Project Structure

```
pdf2txt/
â”œâ”€â”€ adjust_crop.py          # Step 1: Crop PDFs to table region
â”œâ”€â”€ extract_text.py         # Step 2: Extract text & tables â†’ JSON
â”œâ”€â”€ config.py               # Configuration management
â”œâ”€â”€ text_normalization.py   # Text cleaning & BIDI handling
â”œâ”€â”€ geometry_extraction.py  # Table structure extraction
â”œâ”€â”€ requirements.txt        # Dependencies
â””â”€â”€ template1/              # Input PDFs directory
    â””â”€â”€ output/             # Output JSON files
```

## ğŸš€ Quick Start

### Step 1: Crop PDFs
```bash
python adjust_crop.py
```
- Crops all PDFs in `template1/` to table region
- Creates `*_cropped.pdf` files

### Step 2: Extract Text
```bash
python extract_text.py
```
- Processes all `*_cropped.pdf` files
- Extracts text, tables, and geometry
- Saves clean JSON files to `output/`

## ğŸ“¦ Dependencies

Install from `requirements.txt`:
```bash
pip install -r requirements.txt
```

## âš™ï¸ Configuration

Edit `config.py` or modify settings in `extract_text.py`:
- Crop coordinates
- Extraction settings
- Normalization options
- Output formats

## ğŸ“Š Output Format

Each cropped PDF produces one JSON file:
```json
{
  "source_file": "1_cropped.pdf",
  "text": "Extracted and normalized text...",
  "table": {
    "headers": ["Column1", "Column2", ...],
    "rows": [["data1", "data2", ...], ...],
    "row_count": 76,
    "column_count": 34
  },
  "table_info": {
    "rows": 76,
    "columns": 34
  }
}
```

## ğŸ”§ Key Features

- âœ… Handles Persian/Arabic RTL text correctly
- âœ… Converts Persian digits to ASCII
- âœ… Extracts structured table data
- âœ… Clean JSON output format
- âœ… Batch processing support

## ğŸ“ Pipeline Flow

```
Original PDFs â†’ Crop (adjust_crop.py) â†’ Extract (extract_text.py) â†’ JSON Output
```

See `PIPELINE_EXPLANATION.md` for detailed documentation.
